{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf7bdb-52d6-4171-9d34-750007965cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    " Elastic net linear regression uses the penalties from both the lasso and ridge techniques to regularize regression models.\n",
    "    The technique combines both the lasso and ridge regression methods by learning from their shortcomings to improve the regularization of statistical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e285b-3c44-407e-942f-c2c723e37918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "Larger values of alpha imply stronger regularization (less-overfitting, may be underfitting!).\n",
    "Smaller values imply weak regularization (overfitting).\n",
    "We want to build a model that neither overfits nor underfit the data. So, we need to choose an optimal value for alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d5d4a-b0dc-4809-ae4f-c2e7e6e610a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "Elastic Net has several advantages over other regression techniques: \n",
    "1. It can handle multicollinearity, which occurs when two or more features are highly correlated with each other. \n",
    "2. It can also handle datasets with a large number of features and a small number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be794c3c-49b9-46ea-82a2-97eafecd13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "\n",
    "Elastic net can also be used in other applications, such as in sparse PCA, where it obtains principal components that are modified by sparse loadings. \n",
    "The other application is in the kernel elastic net, where the generation of class kernel machines takes place with support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e36b16-8e4b-4298-a472-7be95d8e7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "The coefficients of elastic net regression represent the linear relationship between the features and the target variable, adjusted by the regularization terms. \n",
    "The larger the absolute value of a coefficient, the stronger the effect of the corresponding feature on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dd377-43e4-46d3-8cd0-3f2e1c22db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "Handling missing values in Elastic Net Regression requires careful consideration to ensure that the model can still be trained effectively without introducing bias or reducing predictive performance. Here are several approaches you can consider:\n",
    "\n",
    "Imputation:\n",
    "Mean/Median Imputation: Replace missing values with the mean or median of the feature.\n",
    "Mode Imputation: For categorical features, replace missing values with the mode (most frequent value).\n",
    "K-Nearest Neighbors (KNN) Imputation: Use the values of the nearest neighbors to impute missing values.\n",
    "Predictive Imputation: Train a model (such as a regression or decision tree) to predict missing values based on other features.\n",
    "Deletion:\n",
    "Row Deletion: Remove observations with missing values. This is suitable if the proportion of missing values is small.\n",
    "Column Deletion: Remove features with a high proportion of missing values. However, this approach should be used cautiously as it may discard valuable information.\n",
    "Advanced Techniques:\n",
    "Multiple Imputation: Generate multiple imputed datasets, each with different imputed values, and combine the results to account for uncertainty in imputation.\n",
    "Model-Based Imputation: Utilize a predictive model (such as a regression model) to impute missing values based on the relationships between variables.\n",
    "Handling During Training and Inference:\n",
    "If you're using a library or framework for Elastic Net Regression (e.g., scikit-learn in Python), many implementations handle missing values internally. Ensure to consult the documentation for specifics.\n",
    "If you're implementing Elastic Net Regression from scratch or using a library that doesn't handle missing values, preprocess the data by applying one of the imputation strategies mentioned above before training the model.\n",
    "Evaluate Impact:\n",
    "Assess the impact of different missing data handling strategies on model performance using cross-validation or a separate validation set.\n",
    "Consider the potential biases introduced by imputation methods and whether they align with the assumptions of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e4c22-c521-4cd3-8037-836f4dabbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7\n",
    "Feature selection: Elastic Net Regression can perform feature selection by shrinking the coefficients of irrelevant variables to zero. \n",
    "This results in a model with fewer variables, which is easier to interpret and less prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6d407-a011-4e23-bf26-c178f14171c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 8\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate some sample data for demonstration\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train an Elastic Net Regression model\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # Example hyperparameters\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pickle the trained model\n",
    "with open('elastic_net_model.pkl', 'wb') as f:\n",
    "    pickle.dump(elastic_net, f)\n",
    "\n",
    "# Unpickle the trained model\n",
    "with open('elastic_net_model.pkl', 'rb') as f:\n",
    "    loaded_elastic_net = pickle.load(f)\n",
    "\n",
    "# Now, you can use the loaded model for predictions\n",
    "predictions = loaded_elastic_net.predict(X_test_scaled)\n",
    "\n",
    "# Optionally, you can evaluate the performance of the loaded model\n",
    "score = loaded_elastic_net.score(X_test_scaled, y_test)\n",
    "print(\"R-squared score of the loaded model:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579fa214-718e-4f44-bd9e-be9a8733292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 9\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
